Deep Neural Networks (DNNs) are an extremely successful tool, they are widely
adopted commercially and closely studied academically, however even given the
attention they have gathered there is no comprehensive understanding of how
these models generalize data and provide such impressive performance - in fact
very little is know about how DNNs learn or about their inner workings. Recently
Prof.\ Tishby produced a paper claiming to understand the basic principle of how
DNNs work. He suggested that there are two phases that the network goes trough
while being trained - the fitting phase and the compression phase. During the
fitting phase the network memorizes the training data and makes predictions
based on what it has seen before, during the compression phase the network
generalizes, it forgets the unnecessary information from the training data.
Tishby suggested that the incredible performance that DNNs are able to achieve
is due to this compression phase, and that this process of compression is a
result of randomness inherent in Stochastic gradient descent. Tishby showed this
by looking at DNNs trough the information domain, most notably he used what is
now called the information plane. The information plane summarizes how the
information is flowing trough the DNN, for every neuron layer the plane shows
mutual information it has with the input data and the label data. In his
experiments Tishby has concluded that every layer loses unnecessary information
from the input data and tries to keep information of the label.
%TODO(ag939) possibly explain what an information plane is here.
Tishby made some interesting and significant claims about how DNNs work, however
he did no provide a formal proof, his conclusion are based only on experimental
evidence. 

In our work we look at Tishby`s claim that DNNs compress data and throw away
unnecessary information about the input. We reimplement his experiments as a
form of independent verification, showing that the results Tishby got are robust
and are stable to parameter changes. We also take a look at a paper produced by
Saxe that provides an opposing view to that of Tishby`s. Saxe showed that
compression that Tishby showed is only a result of Tishby`s choice of
activation function for the neural network. He showed that compression only
happens when Tanh activation function is used and does not happen when ReLu is
used.

Lastly, we think that the experiments presented in both papers don't fully align
with the ideas that Tishby presented to us, specifically his idea that weights
should be treated "as if" they are random variables. Tishby`s and Saxe`s
experiment deal with this "as if" random notion quite crudely or try to sidestep
it completely. As a result we devised an experiment that tries to capture this
idea more explicitly, although it is still relatively crude and more work should
be put into it in the future.

\section{The Information plane}

\begin{itemize}
  \item{
      We can look at a NN as a form of a Markov chain that processes the data
      and passes it the next node. For every such node $ t \in T $ we can
      measure it's mutual information with the input patterns $ x \in X $ and
      labels $ y \in Y $. 
      
      $ Y - X \rightarrow T_1 \rightarrow ... \rightarrow T_i  $
      
      When looking at a neural network in this way we can
      say that it's job is to preserve as much information as possible about the
      label, or to minimise information loss about the label during the
      transitions from node to node. 
    }
  \item{
      
    }
\end{itemize}

The information plane is a summary of the DNN`s training process. Lets take a
simple example of a network for which was only trained for one epoch. every node
corresponds to  





















The information plane is a summary of the training process it shows 

\begin{itemize}
  \item{
      show picture of the information plane and explain it
    }
  \item{
      The information plane summarizes how the information is flowing trough the
      DNN, for every neuron layer the plane shows mutual information it has with
      the input data and the label data. 
    }
  \item{
      picture for the information plane for a single epoch
    }
  \item{
      however the information plane is usually shown for the whole training
      process, which helps us make better deductions 
    }
  \item{
      picture for the full information plane.
    }
\end{itemize}
